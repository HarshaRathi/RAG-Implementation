{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c4fd8b-a016-4ea2-81c8-b44029da8c44",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation                       "
   ]
  },
  {
   "cell_type": "raw",
   "id": "280d0306-84e1-4ed0-9694-0909bdb89d79",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "138784a7-83a7-4ff2-83a5-70f7adfe837b",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448ec58-339d-43e4-bc30-f8d95e50c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import langchain\n",
    "from fastapi import HTTPException\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.embedding.model import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import pyPDFLoader, DirectoryLoader\n",
    "from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "from langchain.chains import LLMChain, RetrievalQA, ConversationalRetrievalChain,RetrievalQAWithSourcesChain\n",
    "from db.database import engine, SessionLocal\n",
    "from sqlalchemy.orm import Session\n",
    "from typing import Annotated\n",
    "from fastapi import Depends\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc6866c-bb9f-4df2-9890-7dd4c9f07555",
   "metadata": {},
   "source": [
    "### Read the external Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5caa6-89a3-4662-94e4-7073c238374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Articles/\"\n",
    "try:\n",
    "    loader = DirectoryLoader(data_path, glob = \"**/*.pdf\", loader_cls= PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "except:\n",
    "    raise HTTPException(status_code = 400, detail = 'Unable to find the documents required for the vector')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7a374-f777-482d-8a6e-ff92fc8d872b",
   "metadata": {},
   "source": [
    "### Create a external Documents embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537a901a-f34d-43d7-9492-c2be2c86c0e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embedding_model_instance \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m(\n\u001b[1;32m      2\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-ada-002\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     deployment \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m***********\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     openai_api_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**************************\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     openai_api_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m************************\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     openai_api_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mazure\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     openai_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     embedding_ctx_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8191\u001b[39m,\n\u001b[1;32m      9\u001b[0m     openai_api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*****************************\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     openai_organization \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     allowed_special \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(),\n\u001b[1;32m     12\u001b[0m     disallowed_special \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     13\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m,\n\u001b[1;32m     14\u001b[0m     max_retries \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m     15\u001b[0m     request_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m     headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     tiktoken_model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     18\u001b[0m     show_progress_bar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m     20\u001b[0m     skip_empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \n\u001b[1;32m     22\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embedding_model_instance = OpenAIEmbeddings(\n",
    "    model = \"text-embedding-ada-002\",\n",
    "    deployment = \"***********\",\n",
    "    openai_api_version = \"**************************\",\n",
    "    openai_api_base = \"************************\",\n",
    "    openai_api_type = \"azure\",\n",
    "    openai_proxy = '',\n",
    "    embedding_ctx_length = 8191,\n",
    "    openai_api_key = \"*****************************\",\n",
    "    openai_organization = '',\n",
    "    allowed_special = set(),\n",
    "    disallowed_special = 'all',\n",
    "    chunk_size = 512,\n",
    "    max_retries = 6,\n",
    "    request_timeout = None,\n",
    "    headers = None,\n",
    "    tiktoken_model_name = None,\n",
    "    show_progress_bar = False,\n",
    "    model_kwargs = {},\n",
    "    skip_empty = False\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa82f1f-7183-4317-9011-6e2d287bb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(documents)\n",
    "vectordb = FAISS.from_documents(documents = texts, embedding = embedding_model_instance)\n",
    "vectordb = save_local(\"VectorDb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f6dcf-7297-4933-b1aa-1d381147c468",
   "metadata": {},
   "source": [
    "### Augument the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ac155-72cd-458b-91e3-fd9839247362",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(deployment_name= \"****************\", model_name = 'text-embedding-ada-002', temperature = 1)\n",
    "vectordb = FAISS.load_local(\"VectordDb\")\n",
    "retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={'k':10})\n",
    "message_history = ChatMessageHistory()\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",output_key=\"answer\",chat_memory=message_history,return_message=True)\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(llm=llm,chain_type=\"stuff\",retriever=retriever,memory=memory,return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fffae8b-9122-4a52-84ea-3465ae8ed8ab",
   "metadata": {},
   "source": [
    "### Pass the query and fetch the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e30f5d-84a7-4000-b5af-48f0d13b26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"Query\"\n",
    "print(qa_chain(message)['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
